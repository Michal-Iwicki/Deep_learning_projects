{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f09dd1-4557-4361-a84d-d5c4ef92f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_b0\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loading import TorchTensorFolderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7549ba-1059-4e08-8d9f-d85c92bbbdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(data, filename, column_names):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y_%m_%d_%H.%M\")\n",
    "    filename = f\"{filename}_{timestamp}.csv\"\n",
    "    with open(filename, mode=\"w\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(column_names)  \n",
    "        writer.writerows(data)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a42691-f411-48ee-a707-832e2236e18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(data_size:str=\"full\", target_data:str=\"train\", batch_size:int=16):\n",
    "    # path_to_raw = os.path.join(os.getcwd(), \"data\", \"preprocessed\", data_size, \"raw\", target_data)\n",
    "    path_to_mel = os.path.join(os.getcwd(), \"data\", \"preprocessed\", data_size, \"mel\", target_data)\n",
    "    \n",
    "    # dataset = EnsembleDataset(path_to_raw, path_to_mel)\n",
    "    dataset = TorchTensorFolderDataset(path_to_mel)\n",
    "    # n = len(dataset.labels)\n",
    "    n = len(dataset.class_to_idx)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return loader, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00260497-1ce0-4dd5-9be2-bb59af248cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21cbea2b-2e54-4815-a184-5af403640426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrained_model():\n",
    "    model = efficientnet_b0(weights='EfficientNet_B0_Weights.IMAGENET1K_V1')\n",
    "    \n",
    "    original_conv = model.features[0][0]\n",
    "    new_conv = nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=original_conv.out_channels,\n",
    "        kernel_size=original_conv.kernel_size,\n",
    "        stride=original_conv.stride,\n",
    "        padding=original_conv.padding,\n",
    "        bias=original_conv.bias is not None\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        new_conv.weight[:] = original_conv.weight.mean(dim=1, keepdim=True)\n",
    "    model.features[0][0] = new_conv\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b70e515-8b68-47a1-bf99-dfde17b843c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, train_loader, val_loader, num_epochs=5, patience=3, verbose=False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "\n",
    "    counter = 0\n",
    "    best_val_acc = 0\n",
    "    best_model = model.state_dict()\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if not patience is None and counter >= patience:\n",
    "            print('Patience trigger. End of learning.')\n",
    "            break\n",
    "            \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "        for images, labels in loop:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "    \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "    \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            print(f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"Val Loss:   {val_loss/len(val_loader):.4f}, Val Acc:   {val_acc:.2f}%\\n\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            counter = 0\n",
    "            best_val_acc = val_acc\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc35905-57d5-41af-9d9a-1930acb4d3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "    \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_acc = 100 * test_correct / test_total\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0330c630-b907-46f7-96ac-013c37735870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_learning_rates(times=3, learning_rates=[0.1, 0.05, 0.01, 0.005, 0.001]):\n",
    "    val_loader, _ = get_loader(DATA_SIZE, \"validation\")\n",
    "    test_loader, _ = get_loader(DATA_SIZE, \"test\")\n",
    "    \n",
    "    result = []\n",
    "    column_names = [\"learning_rate\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"test_loss\", \"test_acc\"]\n",
    "    print(*column_names)\n",
    "    \n",
    "    for learning_rate in learning_rates:\n",
    "        for _ in range(times):\n",
    "            train_loader, n = get_loader(DATA_SIZE, \"train\")\n",
    "            \n",
    "            model = get_pretrained_model()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "            \n",
    "            train_model(model, optimizer, train_loader, val_loader, num_epochs=10)\n",
    "            \n",
    "            train_loss, train_acc = test_model(model, train_loader)\n",
    "            val_loss, val_acc = test_model(model, val_loader)\n",
    "            test_loss, test_acc = test_model(model, test_loader)\n",
    "            \n",
    "            result.append((learning_rate, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "            \n",
    "            print(*result[-1])\n",
    "            \n",
    "    save_to_csv(\"results/learning_rates_test.csv\", column_names, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d62d0e-3b41-4692-966e-d881b0a9a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_batch_sizes(times=3, batch_sizes=[16, 32, 64]):\n",
    "    val_loader, _ = get_loader(DATA_SIZE, \"validation\")\n",
    "    test_loader, _ = get_loader(DATA_SIZE, \"test\")\n",
    "    \n",
    "    result = []\n",
    "    column_names = [\"batch_size\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\", \"test_loss\", \"test_acc\"]\n",
    "    print(*column_names)\n",
    "    \n",
    "    for batch_size in batch_sizes:\n",
    "        for _ in range(times):\n",
    "            train_loader, n = get_loader(DATA_SIZE, \"train\", batch_size)\n",
    "            \n",
    "            model = get_pretrained_model()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "            \n",
    "            train_model(model, optimizer, train_loader, val_loader, num_epochs=10)\n",
    "            \n",
    "            train_loss, train_acc = test_model(model, train_loader)\n",
    "            val_loss, val_acc = test_model(model, val_loader)\n",
    "            test_loss, test_acc = test_model(model, test_loader)\n",
    "            \n",
    "            result.append((batch_size, train_loss, train_acc, val_loss, val_acc, test_loss, test_acc))\n",
    "            \n",
    "            print(*result[-1])\n",
    "            \n",
    "    save_to_csv(\"results/batch_sizes_test.csv\", column_names, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddda5827-f6b2-4c6b-a867-be9e6ee7755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]\n",
      "Train Loss: 1.5983, Train Acc: 60.70%\n",
      "Val Loss:   0.3912, Val Acc:   88.45%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]\n",
      "Train Loss: 0.3249, Train Acc: 90.27%\n",
      "Val Loss:   0.2586, Val Acc:   92.04%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]\n",
      "Train Loss: 0.2093, Train Acc: 93.76%\n",
      "Val Loss:   0.2205, Val Acc:   93.65%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]\n",
      "Train Loss: 0.1537, Train Acc: 95.44%\n",
      "Val Loss:   0.1978, Val Acc:   94.16%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1233, Train Acc: 96.26%\n",
      "Val Loss:   0.2277, Val Acc:   93.51%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([5103.514760758728,\n",
       "  1037.3955498253927,\n",
       "  668.3299468760379,\n",
       "  490.8038711771369,\n",
       "  393.6687472044141],\n",
       " [166.26543576689437,\n",
       "  109.90196986513911,\n",
       "  93.72935182449874,\n",
       "  84.05303023275337,\n",
       "  96.77544712425151])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, n = get_loader(DATA_SIZE, \"train\", batch_size=16)\n",
    "val_loader, _ = get_loader(DATA_SIZE, \"validation\")\n",
    "model = get_pretrained_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "train_model(model, optimizer, train_loader, val_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afdfa5c-7a73-45df-af22-56df1036dc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]\n",
      "Train Loss: 0.6204, Train Acc: 83.08%\n",
      "Val Loss:   0.3020, Val Acc:   91.67%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5]\n",
      "Train Loss: 0.2388, Train Acc: 93.07%\n",
      "Val Loss:   0.2097, Val Acc:   93.70%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5]\n",
      "Train Loss: 0.1853, Train Acc: 94.70%\n",
      "Val Loss:   0.1769, Val Acc:   94.79%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5]\n",
      "Train Loss: 0.1577, Train Acc: 95.40%\n",
      "Val Loss:   0.2058, Val Acc:   94.62%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5]\n",
      "Train Loss: 0.1355, Train Acc: 96.06%\n",
      "Val Loss:   0.1846, Val Acc:   94.85%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1980.8902250328101,\n",
       "  762.5810027393163,\n",
       "  591.5424284026376,\n",
       "  503.47922662697965,\n",
       "  432.75208029104397],\n",
       " [128.33013684261823,\n",
       "  89.142952112481,\n",
       "  75.19214589620242,\n",
       "  87.47840556570736,\n",
       "  78.44605588639388])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader, n = get_loader(DATA_SIZE, \"train\", batch_size=16)\n",
    "val_loader, _ = get_loader(DATA_SIZE, \"validation\")\n",
    "model = get_pretrained_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, optimizer, train_loader, val_loader, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2464753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]\n",
      "Train Loss: 0.6007, Train Acc: 83.57%\n",
      "Val Loss:   0.2776, Val Acc:   91.89%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]\n",
      "Train Loss: 0.2418, Train Acc: 92.98%\n",
      "Val Loss:   0.2813, Val Acc:   91.97%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]\n",
      "Train Loss: 0.1909, Train Acc: 94.45%\n",
      "Val Loss:   0.2228, Val Acc:   93.29%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]\n",
      "Train Loss: 0.1606, Train Acc: 95.34%\n",
      "Val Loss:   0.1979, Val Acc:   94.42%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]\n",
      "Train Loss: 0.1354, Train Acc: 96.00%\n",
      "Val Loss:   0.1989, Val Acc:   94.19%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]\n",
      "Train Loss: 0.1234, Train Acc: 96.39%\n",
      "Val Loss:   0.1969, Val Acc:   94.95%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]\n",
      "Train Loss: 0.1120, Train Acc: 96.70%\n",
      "Val Loss:   0.1839, Val Acc:   95.13%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]\n",
      "Train Loss: 0.1032, Train Acc: 97.01%\n",
      "Val Loss:   0.1891, Val Acc:   95.15%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]\n",
      "Train Loss: 0.0975, Train Acc: 97.16%\n",
      "Val Loss:   0.1811, Val Acc:   94.60%\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]\n",
      "Train Loss: 0.0881, Train Acc: 97.44%\n",
      "Val Loss:   0.2028, Val Acc:   94.82%\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1918.0213053759653,\n",
       "  772.0496782499831,\n",
       "  609.4463884253637,\n",
       "  512.8738083560165,\n",
       "  432.27412884963996,\n",
       "  394.1068180496659,\n",
       "  357.5698853743961,\n",
       "  329.3669393299715,\n",
       "  311.3240869319525,\n",
       "  281.4477150152161],\n",
       " [117.98939325893298,\n",
       "  119.55551666021347,\n",
       "  94.6768495227152,\n",
       "  84.12303739748313,\n",
       "  84.53763370207889,\n",
       "  83.70196658827626,\n",
       "  78.17026244670888,\n",
       "  80.38090721858316,\n",
       "  76.98737024701586,\n",
       "  86.20373453723096])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_loader(data_size:str=\"full\", target_data:str=\"train\", batch_size:int=16):\n",
    "    # path_to_raw = os.path.join(os.getcwd(), \"data\", \"preprocessed\", data_size, \"raw\", target_data)\n",
    "    path_to_mel = os.path.join(os.getcwd(), \"data\", \"preprocessed\",\"denoised\", data_size, \"mel\", target_data)\n",
    "    \n",
    "    # dataset = EnsembleDataset(path_to_raw, path_to_mel)\n",
    "    dataset = TorchTensorFolderDataset(path_to_mel)\n",
    "    # n = len(dataset.labels)\n",
    "    n = len(dataset.class_to_idx)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=False)\n",
    "\n",
    "    return loader, n\n",
    "\n",
    "train_loader, n = get_loader('', \"train\", batch_size=16)\n",
    "val_loader, _ = get_loader('', \"validation\")\n",
    "model = get_pretrained_model()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train_model(model, optimizer, train_loader, val_loader, verbose=True, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ae3fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
