{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579e5579-96a3-4617-af39-b77b566a0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tester import test_learning_rates, test_batch_sizes, test_weights_decays\n",
    "from EfficientNet_implementation import get_pretrained_model, train_model, test_model\n",
    "from CNN_transfomers_implementation import Mel_transformer, RawAudioTransformer, train_transformer, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257d0792-10f4-4c84-941c-27475764c27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_SIZE = \"sample\"\n",
    "DENOISED = False\n",
    "USE_MEL = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34437629-2a0f-41af-8fcf-adb66ec06e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mel_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b88a6a93-449c-407e-8c2b-7482928041b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate train_loss train_acc val_loss val_acc test_loss test_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                            "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (200, 200) at dimension 2 of input [1, 2048, 101]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtest_learning_rates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_transformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenoised\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDENOISED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_mel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mUSE_MEL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\studies\\masters\\semeter_1\\DL\\Deep_learning_projects\\project_2\\tester.py:45\u001b[39m, in \u001b[36mtest_learning_rates\u001b[39m\u001b[34m(model, train_model, test_model, times, learning_rates, data_size, denoised, use_mel)\u001b[39m\n\u001b[32m     41\u001b[39m train_loader = get_loader(data_size, denoised, use_mel, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m train_loss, train_acc = test_model(model, train_loader)\n\u001b[32m     48\u001b[39m val_loss, val_acc = test_model(model, val_loader)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\studies\\masters\\semeter_1\\DL\\Deep_learning_projects\\project_2\\CNN_transfomers_implementation.py:135\u001b[39m, in \u001b[36mtrain_transformer\u001b[39m\u001b[34m(model, optimizer, train_loader, val_loader, num_epochs, patience, verbose)\u001b[39m\n\u001b[32m    132\u001b[39m x, y = x.to(device), y.to(device)\n\u001b[32m    134\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m loss = criterion(outputs, y)\n\u001b[32m    137\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\studies\\masters\\semeter_1\\DL\\Deep_learning_projects\\project_2\\CNN_transfomers_implementation.py:51\u001b[39m, in \u001b[36mMel_transformer.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# x: (B, 16000)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmelspec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, n_mels, T)\u001b[39;00m\n\u001b[32m     52\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.db(x)  \u001b[38;5;66;03m# (B, n_mels, T)\u001b[39;00m\n\u001b[32m     54\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.cnn(x)  \u001b[38;5;66;03m# (B, 64, n_mels, T)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torchaudio\\transforms\\_transforms.py:619\u001b[39m, in \u001b[36mMelSpectrogram.forward\u001b[39m\u001b[34m(self, waveform)\u001b[39m\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) -> Tensor:\n\u001b[32m    612\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[33;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    617\u001b[39m \u001b[33;03m        Tensor: Mel frequency spectrogram of size (..., ``n_mels``, time).\u001b[39;00m\n\u001b[32m    618\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     specgram = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m     mel_specgram = \u001b[38;5;28mself\u001b[39m.mel_scale(specgram)\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mel_specgram\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torchaudio\\transforms\\_transforms.py:110\u001b[39m, in \u001b[36mSpectrogram.forward\u001b[39m\u001b[34m(self, waveform)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, waveform: Tensor) -> Tensor:\n\u001b[32m    101\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m        waveform (Tensor): Tensor of audio of dimension (..., time).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    108\u001b[39m \u001b[33;03m        Fourier bins, and time is the number of window hops (n_frame).\u001b[39;00m\n\u001b[32m    109\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspectrogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpower\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43monesided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torchaudio\\functional\\functional.py:126\u001b[39m, in \u001b[36mspectrogram\u001b[39m\u001b[34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized, center, pad_mode, onesided, return_complex)\u001b[39m\n\u001b[32m    123\u001b[39m waveform = waveform.reshape(-\u001b[32m1\u001b[39m, shape[-\u001b[32m1\u001b[39m])\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m spec_f = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhop_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwin_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnormalized\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_length_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43monesided\u001b[49m\u001b[43m=\u001b[49m\u001b[43monesided\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# unpack batch\u001b[39;00m\n\u001b[32m    140\u001b[39m spec_f = spec_f.reshape(shape[:-\u001b[32m1\u001b[39m] + spec_f.shape[-\u001b[32m2\u001b[39m:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\functional.py:707\u001b[39m, in \u001b[36mstft\u001b[39m\u001b[34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided, return_complex)\u001b[39m\n\u001b[32m    705\u001b[39m     extended_shape = [\u001b[32m1\u001b[39m] * (\u001b[32m3\u001b[39m - signal_dim) + \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m    706\u001b[39m     pad = \u001b[38;5;28mint\u001b[39m(n_fft // \u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextended_shape\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28minput\u001b[39m.view(\u001b[38;5;28minput\u001b[39m.shape[-signal_dim:])\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _VF.stft(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    710\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    711\u001b[39m     n_fft,\n\u001b[32m   (...)\u001b[39m\u001b[32m    717\u001b[39m     return_complex,\n\u001b[32m    718\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\SCIENCE\\PROJECTS\\python\\jupyter\\.venv\\Lib\\site-packages\\torch\\nn\\functional.py:5209\u001b[39m, in \u001b[36mpad\u001b[39m\u001b[34m(input, pad, mode, value)\u001b[39m\n\u001b[32m   5202\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mreplicate\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   5203\u001b[39m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[32m   5204\u001b[39m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[32m   5205\u001b[39m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[32m   5206\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\n\u001b[32m   5207\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtorch._decomp.decompositions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   5208\u001b[39m             )._replication_pad(\u001b[38;5;28minput\u001b[39m, pad)\n\u001b[32m-> \u001b[39m\u001b[32m5209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (200, 200) at dimension 2 of input [1, 2048, 101]"
     ]
    }
   ],
   "source": [
    "test_learning_rates(model, train_transformer, evaluate_model, data_size=DATA_SIZE, denoised=DENOISED, use_mel=USE_MEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd39f81-a83f-4bf9-ad5d-a5f833ef9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_sizes(model, train_model, test_model, data_size=DATA_SIZE, denoised=DENOISED, use_mel=USE_MEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5cc467-fac6-4282-b5a3-acd7deac710b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_weights_decays(model, train_model, test_model, data_size=DATA_SIZE, denoised=DENOISED, use_mel=USE_MEL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
