{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1d514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class NoiseVoiceClassificationDataset(Dataset):\n",
    "    def __init__(self, folder_noise, folder_voice, seed=42, prop=1):\n",
    "        self.samples = []\n",
    "\n",
    "        noise_paths = [os.path.join(folder_noise, f) for f in os.listdir(folder_noise) if f.endswith('.pt')]\n",
    "\n",
    "        voice_paths = []\n",
    "        for root, _, files in os.walk(folder_voice):\n",
    "            for f in files:\n",
    "                if f.endswith('.pt'):\n",
    "                    voice_paths.append(os.path.join(root, f))\n",
    "\n",
    "        num_noise = len(noise_paths)\n",
    "\n",
    "        # Sample voice audios with size prop*num_noise\n",
    "        rnd = random.Random(seed)\n",
    "        voice_paths_sampled = rnd.sample(voice_paths, k=min(prop * num_noise, len(voice_paths)))\n",
    "\n",
    "        self.samples.extend([(p, 0) for p in noise_paths])\n",
    "        self.samples.extend([(p, 1) for p in voice_paths_sampled])\n",
    "\n",
    "        rnd.shuffle(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        tensor = torch.load(path, weights_only=False)\n",
    "        return tensor, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "def load_dataloaders(noise_dir, voice_dir, seed=42, batchsize=16, prop=1):\n",
    "    splits = ['train', 'validation', 'test']\n",
    "    loaders = {}\n",
    "\n",
    "    for i, split in enumerate(splits):\n",
    "        noise_folder = os.path.join(noise_dir, split)\n",
    "        voice_folder = os.path.join(voice_dir, split)\n",
    "\n",
    "        dataset = NoiseVoiceClassificationDataset(noise_folder, voice_folder, seed=seed + i, prop=prop)\n",
    "\n",
    "        loaders[split] = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batchsize,\n",
    "            shuffle=(True if split == 'train' else False)\n",
    "        )\n",
    "\n",
    "    return loaders['train'], loaders['validation'], loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b1ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dir = os.path.join(os.getcwd(), \"data\", \"preprocessed\", \"noise\", \"standard\", \"raw\")\n",
    "voice_dir = os.path.join(os.getcwd(), \"data\", \"preprocessed\", \"standard\",\"raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69806bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_transfomers_implementation import Mel_transformer, train_transformer\n",
    "\n",
    "train, val, test = load_dataloaders(noise_dir, voice_dir, batchsize=16, prop=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7d982f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20:   0%|          | 0/263 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 0.0698 | Train Acc: 0.9860 | Val Acc: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.0192 | Train Acc: 0.9971 | Val Acc: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.0168 | Train Acc: 0.9964 | Val Acc: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.0096 | Train Acc: 0.9981 | Val Acc: 0.9979\n",
      "Early stopping triggered at epoch 4\n",
      "Best Val Acc: 0.9986\n"
     ]
    }
   ],
   "source": [
    "spect_model = Mel_transformer(num_classes=30)\n",
    "spect_model = train_transformer(spect_model, train, val, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b03364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9936, 0.0881)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CNN_transfomers_implementation import evaluate_model\n",
    "\n",
    "evaluate_model(spect_model, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0baca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
