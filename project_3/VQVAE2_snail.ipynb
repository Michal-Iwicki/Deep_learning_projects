{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ea4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.embedding.weight.data.uniform_(-1/num_embeddings, 1/num_embeddings)\n",
    "        self.commitment_cost = commitment_cost\n",
    "\n",
    "    def forward(self, z):\n",
    "        z_flat = z.permute(0, 2, 3, 1).contiguous().view(-1, self.embedding_dim)\n",
    "        distances = (\n",
    "            torch.sum(z_flat ** 2, dim=1, keepdim=True)\n",
    "            - 2 * torch.matmul(z_flat, self.embedding.weight.t())\n",
    "            + torch.sum(self.embedding.weight ** 2, dim=1)\n",
    "        )\n",
    "        indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(indices.size(0), self.num_embeddings, device=z.device)\n",
    "        encodings.scatter_(1, indices, 1)\n",
    "\n",
    "        quantized = torch.matmul(encodings, self.embedding.weight).view(\n",
    "            z.shape[0], z.shape[2], z.shape[3], self.embedding_dim\n",
    "        ).permute(0, 3, 1, 2)\n",
    "\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), z)\n",
    "        q_latent_loss = F.mse_loss(quantized, z.detach())\n",
    "        loss = q_latent_loss + self.commitment_cost * e_latent_loss\n",
    "        quantized = z + (quantized - z).detach()\n",
    "        indices = indices.view(z.shape[0], z.shape[2], z.shape[3])\n",
    "        return quantized, loss, indices\n",
    "\n",
    "class VQVAE2(nn.Module):\n",
    "    def __init__(self, num_embeddings=512, embedding_dim=64):\n",
    "        super().__init__()\n",
    "        # Encoder bottom -> z_b\n",
    "        self.enc_b = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(128, embedding_dim, 3, 1, 1)\n",
    "        )\n",
    "        # Encoder top -> z_t\n",
    "        self.enc_t = nn.Sequential(\n",
    "            nn.Conv2d(embedding_dim, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(128, embedding_dim, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.quant_t = VectorQuantizer(num_embeddings, embedding_dim, 0.25)\n",
    "        self.quant_b = VectorQuantizer(num_embeddings, embedding_dim, 0.25)\n",
    "\n",
    "        self.dec_t = nn.Sequential(\n",
    "            nn.ConvTranspose2d(embedding_dim, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(128, embedding_dim, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(2 * embedding_dim, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.Conv2d(64, 3, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_b = self.enc_b(x)\n",
    "        z_t = self.enc_t(z_b)\n",
    "\n",
    "        quant_t, loss_t, idx_t = self.quant_t(z_t)\n",
    "        dec_t = self.dec_t(quant_t)\n",
    "\n",
    "        z_b_combined = z_b + dec_t\n",
    "        quant_b, loss_b, idx_b = self.quant_b(z_b_combined)\n",
    "\n",
    "        x_recon = self.dec(torch.cat([quant_b, dec_t], dim=1))\n",
    "        return x_recon, loss_t + loss_b\n",
    "\n",
    "    def encode_indices(self, x):\n",
    "        z_b = self.enc_b(x)\n",
    "        z_t = self.enc_t(z_b)\n",
    "        _, _, idx_t = self.quant_t(z_t)\n",
    "        dec_t = self.dec_t(self.quant_t(z_t)[0])\n",
    "        z_b_combined = z_b + dec_t\n",
    "        _, _, idx_b = self.quant_b(z_b_combined)\n",
    "        return idx_t, idx_b\n",
    "\n",
    "    def decode_indices(self, idx_t, idx_b):\n",
    "        emb_t = self.quant_t.embedding(idx_t).permute(0, 3, 1, 2)\n",
    "        dec_t = self.dec_t(emb_t)\n",
    "        emb_b = self.quant_b.embedding(idx_b).permute(0, 3, 1, 2)\n",
    "        recon = self.dec(torch.cat([emb_b, dec_t], dim=1))\n",
    "        return recon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5362989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PixelSNAIL(nn.Module):\n",
    "    def __init__(self, num_embeddings, hidden_dim, size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, hidden_dim, 7, padding=3),\n",
    "            nn.ReLU(),\n",
    "            *[nn.Sequential(nn.Conv2d(hidden_dim, hidden_dim, 3, padding=1), nn.ReLU()) for _ in range(8)],\n",
    "            nn.Conv2d(hidden_dim, num_embeddings, 1)\n",
    "        )\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def sample(self, device, num_samples):\n",
    "        samples = torch.zeros((num_samples, 1, self.size, self.size), dtype=torch.long).to(device)\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                with torch.no_grad():\n",
    "                    logits = self(samples.float())\n",
    "                    probs = torch.softmax(logits[:, :, i, j], dim=1)\n",
    "                    samples[:, 0, i, j] = torch.multinomial(probs, 1).squeeze()\n",
    "        return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9dc84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 1/20: 100%|██████████| 467/467 [00:14<00:00, 32.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 2/20: 100%|██████████| 467/467 [00:13<00:00, 35.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 3/20: 100%|██████████| 467/467 [00:12<00:00, 36.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 4/20: 100%|██████████| 467/467 [00:12<00:00, 36.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 5/20: 100%|██████████| 467/467 [00:12<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 6/20: 100%|██████████| 467/467 [00:12<00:00, 36.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 7/20: 100%|██████████| 467/467 [00:12<00:00, 36.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 8/20: 100%|██████████| 467/467 [00:12<00:00, 36.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 9/20: 100%|██████████| 467/467 [00:12<00:00, 36.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 10/20: 100%|██████████| 467/467 [00:12<00:00, 36.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 11/20: 100%|██████████| 467/467 [00:12<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 12/20: 100%|██████████| 467/467 [00:12<00:00, 36.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 13/20: 100%|██████████| 467/467 [00:12<00:00, 36.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 14/20: 100%|██████████| 467/467 [00:12<00:00, 36.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 15/20: 100%|██████████| 467/467 [00:12<00:00, 36.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 16/20: 100%|██████████| 467/467 [00:12<00:00, 36.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 17/20: 100%|██████████| 467/467 [00:12<00:00, 36.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 18/20: 100%|██████████| 467/467 [00:12<00:00, 37.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 19/20: 100%|██████████| 467/467 [00:12<00:00, 36.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VQ-VAE2 Epoch 20/20: 100%|██████████| 467/467 [00:12<00:00, 36.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: avg loss = 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding latents: 100%|██████████| 467/467 [00:10<00:00, 43.21it/s]\n",
      "PixelSNAIL Top Epoch 1/10: 100%|██████████| 467/467 [00:01<00:00, 257.66it/s]\n",
      "PixelSNAIL Top Epoch 2/10: 100%|██████████| 467/467 [00:01<00:00, 260.38it/s]\n",
      "PixelSNAIL Top Epoch 3/10: 100%|██████████| 467/467 [00:01<00:00, 257.12it/s]\n",
      "PixelSNAIL Top Epoch 4/10: 100%|██████████| 467/467 [00:01<00:00, 265.25it/s]\n",
      "PixelSNAIL Top Epoch 5/10: 100%|██████████| 467/467 [00:01<00:00, 264.77it/s]\n",
      "PixelSNAIL Top Epoch 6/10: 100%|██████████| 467/467 [00:01<00:00, 276.20it/s]\n",
      "PixelSNAIL Top Epoch 7/10: 100%|██████████| 467/467 [00:01<00:00, 272.10it/s]\n",
      "PixelSNAIL Top Epoch 8/10: 100%|██████████| 467/467 [00:01<00:00, 263.23it/s]\n",
      "PixelSNAIL Top Epoch 9/10: 100%|██████████| 467/467 [00:01<00:00, 259.35it/s]\n",
      "PixelSNAIL Top Epoch 10/10: 100%|██████████| 467/467 [00:01<00:00, 257.27it/s]\n",
      "PixelSNAIL Bottom Epoch 1/10: 100%|██████████| 467/467 [00:01<00:00, 251.39it/s]\n",
      "PixelSNAIL Bottom Epoch 2/10: 100%|██████████| 467/467 [00:01<00:00, 259.53it/s]\n",
      "PixelSNAIL Bottom Epoch 3/10: 100%|██████████| 467/467 [00:01<00:00, 271.93it/s]\n",
      "PixelSNAIL Bottom Epoch 4/10: 100%|██████████| 467/467 [00:01<00:00, 271.41it/s]\n",
      "PixelSNAIL Bottom Epoch 5/10: 100%|██████████| 467/467 [00:01<00:00, 277.77it/s]\n",
      "PixelSNAIL Bottom Epoch 6/10: 100%|██████████| 467/467 [00:01<00:00, 273.05it/s]\n",
      "PixelSNAIL Bottom Epoch 7/10: 100%|██████████| 467/467 [00:01<00:00, 276.82it/s]\n",
      "PixelSNAIL Bottom Epoch 8/10: 100%|██████████| 467/467 [00:01<00:00, 267.32it/s]\n",
      "PixelSNAIL Bottom Epoch 9/10: 100%|██████████| 467/467 [00:01<00:00, 264.73it/s]\n",
      "PixelSNAIL Bottom Epoch 10/10: 100%|██████████| 467/467 [00:01<00:00, 263.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling latents...\n",
      "Saved: generated/generated_cats_vqvae2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Transformacje danych\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "dataset = ImageFolder(\"data\", transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Model\n",
    "vqvae = VQVAE2().to(device)\n",
    "optimizer = torch.optim.Adam(vqvae.parameters(), lr=2e-4)\n",
    "\n",
    "# === Trening VQ-VAE-2 ===\n",
    "for epoch in range(20):\n",
    "    vqvae.train()\n",
    "    total_loss = 0.0\n",
    "    for x, _ in tqdm(loader, desc=f\"VQ-VAE2 Epoch {epoch+1}/20\"):\n",
    "        x = x.to(device)\n",
    "        x_recon, loss = vqvae(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}: avg loss = {avg_loss:.4f}\")\n",
    "\n",
    "    # Zapis przykładowych rekonstrukcji co 5 epok\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        vqvae.eval()\n",
    "        with torch.no_grad():\n",
    "            sample = next(iter(loader))[0][:8].to(device)\n",
    "            recon, _ = vqvae(sample)\n",
    "            save_image(torch.cat([sample, recon], dim=0), f\"recon_epoch{epoch+1}.png\", nrow=8)\n",
    "\n",
    "# === Zbieranie kodów latentnych ===\n",
    "vqvae.eval()\n",
    "idx_t_all, idx_b_all = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, _ in tqdm(loader, desc=\"Encoding latents\"):\n",
    "        x = x.to(device)\n",
    "        idx_t, idx_b = vqvae.encode_indices(x)\n",
    "        idx_t_all.append(idx_t)\n",
    "        idx_b_all.append(idx_b)\n",
    "\n",
    "idx_t_all = torch.cat(idx_t_all)\n",
    "idx_b_all = torch.cat(idx_b_all)\n",
    "\n",
    "# === Trening PixelSNAIL ===\n",
    "pixelsnail_t = PixelSNAIL(num_embeddings=512, hidden_dim=64, size=idx_t_all.shape[1]).to(device)\n",
    "pixelsnail_b = PixelSNAIL(num_embeddings=512, hidden_dim=64, size=idx_b_all.shape[1]).to(device)\n",
    "\n",
    "opt_t = torch.optim.Adam(pixelsnail_t.parameters(), lr=2e-4)\n",
    "opt_b = torch.optim.Adam(pixelsnail_b.parameters(), lr=2e-4)\n",
    "\n",
    "# Pomocnicze dataloadery z kodami indeksów\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "loader_t = DataLoader(TensorDataset(idx_t_all), batch_size=64, shuffle=True)\n",
    "loader_b = DataLoader(TensorDataset(idx_b_all), batch_size=64, shuffle=True)\n",
    "\n",
    "# === Trening PixelSNAIL Top ===\n",
    "for epoch in range(10):\n",
    "    pixelsnail_t.train()\n",
    "    for (x_t,) in tqdm(loader_t, desc=f\"PixelSNAIL Top Epoch {epoch+1}/10\"):\n",
    "        x_t = x_t.to(device).unsqueeze(1).float()  # [B, 1, H, W]\n",
    "        logits = pixelsnail_t(x_t)\n",
    "        target = x_t.squeeze(1).long()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target)\n",
    "\n",
    "        opt_t.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_t.step()\n",
    "\n",
    "# === Trening PixelSNAIL Bottom ===\n",
    "for epoch in range(10):\n",
    "    pixelsnail_b.train()\n",
    "    for (x_b,) in tqdm(loader_b, desc=f\"PixelSNAIL Bottom Epoch {epoch+1}/10\"):\n",
    "        x_b = x_b.to(device).unsqueeze(1).float()\n",
    "        logits = pixelsnail_b(x_b)\n",
    "        target = x_b.squeeze(1).long()\n",
    "        loss = torch.nn.functional.cross_entropy(logits, target)\n",
    "\n",
    "        opt_b.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_b.step()\n",
    "\n",
    "# === Generowanie ===\n",
    "print(\"Sampling latents...\")\n",
    "pixelsnail_t.eval()\n",
    "pixelsnail_b.eval()\n",
    "\n",
    "idx_t_sample = pixelsnail_t.sample(device, 16).squeeze(1).long()\n",
    "idx_b_sample = pixelsnail_b.sample(device, 16).squeeze(1).long()\n",
    "\n",
    "vqvae.eval()\n",
    "with torch.no_grad():\n",
    "    recon = vqvae.decode_indices(idx_t_sample, idx_b_sample)\n",
    "\n",
    "os.makedirs(\"generated\", exist_ok=True)\n",
    "save_image(recon, \"generated/generated_cats_vqvae2.png\", nrow=4)\n",
    "print(\"Saved: generated/generated_cats_vqvae2.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80da2fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
