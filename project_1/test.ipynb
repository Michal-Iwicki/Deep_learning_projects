{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class PNGDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for label in os.listdir(root_dir):\n",
    "            label_path = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                for file in os.listdir(label_path):\n",
    "                    if file.endswith('.png'):\n",
    "                        self.files.append(os.path.join(label_path, file))\n",
    "                        self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Funkcja do ładowania danych\n",
    "\n",
    "def load_png_images(root_dir, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),          # Konwersja do tensorów\n",
    "        transforms.Normalize((0.5,), (0.5,))  # Normalizacja\n",
    "    ])\n",
    "    \n",
    "    dataset = PNGDataset(root_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_random_png():\n",
    "\n",
    "    root_dir = r\"C:\\Users\\Micha\\SEM1_projects\\Deep_learning_projects\\project_1\\data\\test\"\n",
    "    dataloader = load_png_images(root_dir, batch_size=1)  \n",
    "    data_iter = iter(dataloader)\n",
    "    image, label = next(data_iter)\n",
    "\n",
    "    image = image.squeeze(0) \n",
    "    image = image * 0.5 + 0.5  \n",
    "    image = image.permute(1, 2, 0).numpy()  \n",
    "    image = (image * 255).astype(np.uint8) \n",
    "\n",
    "    # Wyświetlenie obrazu\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Label: {label[0]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIghJREFUeJzt3XuQnAW55/Gnr9M93T33KwPJZMiNKDExMXhiWBBxswiVBRXdnK2lsu5GyrIEqfJC1ZZE//IfLcOKhVxUQKIeBeSgUMnxCChKSIJgCIHJfSbJZDL3a1+nu9/9w+KpjRF5HgWDnu+nyrLs/Hh8p9+3+9dvkn4IBUEQCAAAIhI+1wcAAHj7oBQAAIpSAAAoSgEAoCgFAICiFAAAilIAAChKAQCgKAUAgKIU8Hehr69PQqGQfO1rX3vTZj799NMSCoXk6aef/otnfP/735elS5dKLBaThoaGN+3YgHOFUsBb5r777pNQKCTPP//8uT6Ut0Rvb69s2rRJLrzwQrnnnnvk7rvvPteHBPzVouf6AIC/V08//bRUq1W5/fbbZeHChef6cIA3BXcKwF9oeHhYROQNf9soCALJ5/N/gyMC/nqUAs6pUqkkt912m6xatUrq6+sllUrJpZdeKk899dTr/jPf+MY3ZP78+ZJMJuWyyy6Tl19++axMb2+vfPSjH5WmpiZJJBKyevVqeeyxx97weHK5nPT29sro6OifzXV3d8uWLVtERKS1tVVCoZB8+ctf1l+75pprZMeOHbJ69WpJJpNy1113iYjI0aNH5frrr5empiapra2V9773vfL444+fNb+/v182bNggqVRK2tra5JZbbpEdO3b81X8GArwRfvsI59T09LTce++9snHjRtm8ebPMzMzId77zHVm/fr3s3r1bVqxYcUb+gQcekJmZGfn0pz8thUJBbr/9drniiitk37590t7eLiIi+/fvl/e9733S1dUlt956q6RSKfnxj38s1157rTz88MNy3XXXve7x7N69W97//vfLli1b9E3+T9m6das88MAD8tOf/lTuvPNOSafTsnz5cv31AwcOyMaNG+XGG2+UzZs3y5IlS2RoaEjWrl0ruVxObrrpJmlubpb7779fNmzYIA899JAeVzablSuuuEIGBwfl5ptvlo6ODvnBD37wZ4sSeNMEwFvke9/7XiAiwZ49e143Uy6Xg2KxeMZjExMTQXt7e/CJT3xCHzt27FggIkEymQxOnjypj+/atSsQkeCWW27Rxz7wgQ8EF198cVAoFPSxarUarF27Nli0aJE+9tRTTwUiEjz11FNnPbZly5Y3/Pm2bNkSiEgwMjJyxuPz588PRCTYvn37GY9/9rOfDUQkeOaZZ/SxmZmZYMGCBUF3d3dQqVSCIAiCr3/964GIBI8++qjm8vl8sHTp0rOOF3iz8dtHOKcikYjE43EREalWqzI+Pi7lcllWr14tL7zwwln5a6+9Vrq6uvR/r1mzRi655BJ54oknRERkfHxcnnzySfnYxz4mMzMzMjo6KqOjozI2Nibr16+XQ4cOycDAwOsez+WXXy5BEPzZuwSLBQsWyPr168947IknnpA1a9bIunXr9LF0Oi2f/OQnpa+vT1555RUREdm+fbt0dXXJhg0bNJdIJGTz5s1/1TEBFpQCzrn7779fli9fLolEQpqbm6W1tVUef/xxmZqaOiu7aNGisx5bvHix9PX1iYjI4cOHJQgC+dKXviStra1n/Oe1PwN47Q+I30oLFiw467H+/n5ZsmTJWY9fdNFF+uuv/feFF14ooVDojBx/wwl/C/yZAs6pBx98UDZt2iTXXnutfP7zn5e2tjaJRCLy1a9+VY4cOeKeV61WRUTkc5/73Fmf1F/zt3hzTSaTb/n/B/BWoBRwTj300EPS09MjjzzyyBmfjF/7VP/HDh06dNZjBw8elO7ubhER6enpERGRWCwmV1555Zt/wH+F+fPny4EDB856vLe3V3/9tf9+5ZVXJAiCM56Tw4cP/20OFP+h8dtHOKcikYiI/OHv8r9m165dsnPnzj+Zf/TRR8/4M4Hdu3fLrl275KqrrhIRkba2Nrn88svlrrvuksHBwbP++ZGRkT97PNa/kvqX+NCHPiS7d+8+42fLZrNy9913S3d3tyxbtkxERNavXy8DAwNn/BXaQqEg99xzz5t+TMAf404Bb7nvfve7sn379rMev/nmm+Waa66RRx55RK677jq5+uqr5dixY/Ltb39bli1bJrOzs2f9MwsXLpR169bJpz71KSkWi7J161Zpbm6WL3zhC5r51re+JevWrZOLL75YNm/eLD09PTI0NCQ7d+6UkydPyt69e1/3WK1/JfUvceutt8oPf/hDueqqq+Smm26SpqYmuf/+++XYsWPy8MMPSzj8h89oN954o9xxxx2yceNGufnmm6Wzs1O2bdsmiURCROSsP2sA3kyUAt5yd9555598fNOmTbJp0yY5ffq03HXXXbJjxw5ZtmyZPPjgg/KTn/zkT35J64YbbpBwOCxbt26V4eFhWbNmjdxxxx3S2dmpmWXLlsnzzz8vX/nKV+S+++6TsbExaWtrk5UrV8ptt932Vv2Yb6i9vV2effZZ+eIXvyjf/OY3pVAoyPLly+VnP/uZXH311ZpLp9Py5JNPymc+8xm5/fbbJZ1Oyw033CBr166Vj3zkI1oOwFshFPz/9+0A3ra2bt0qt9xyi5w8efKMv5YLvJkoBeBtKJ/Pn/E3mAqFgqxcuVIqlYocPHjwHB4Z/tHx20fA29CHP/xhmTdvnqxYsUKmpqbkwQcflN7eXtm2bdu5PjT8g6MUgLeh9evXy7333ivbtm2TSqUiy5Ytkx/96Efy8Y9//FwfGv7B8dtHAADF9xQAAIpSAAAo858pPPXIN12D58pz5mxdQ7trdigSN2ezM9Ou2cmY/XfTqlJwzQ4FMXM2nsy4Zgch+3MiIlLKjpuzoVDENTtSY/979Nn8n/+G8R+rj9uvq5zz3E9nT7ny8USjOdtQt9Q3u7bBnC3lfAv+sjn785KsbXHNLs2VzNlDEy+5ZscivtdEXaXJnI2EfJ+P4zX211sg9mtWRCSbff0tvn8sFMq6Zl/3iXvfMMOdAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAlHn3USXw7b+pSabN2XDYvhNIRCQasf9rIKKxGtdsqdh38YQSta7Rsah9d0tNrX2vjojIXNG3hylw/MvfI3Hfz1nj2Asj4tutUyxMmbPVUN41O13b7MqHQilzNl+suGZH4/bzWa76PtuFwvbzEwnZdxmJiJQlZ86Wqr6dQOWCb89PomrfwVXxvb1J3PN+WPWd+1LJ/rxUwr7ZFtwpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFDmfRGJWvuKBhGRZG2DORsOVV2zy2XHV7srRdfsUsG+GiGoJl2zY/X29QLhkO9799GQ7+vuocD+nIfEt+og4jj2qPiOuyL2lSixhG9tRSrmu8Ynx8bN2Upx0DV7umh/DktiXykjIpLPT5qz5ZJnZYnIbNm+5kIKgWt2fsQxW0QiIftn3lDS9/m4XGu/DluaznPNronbV/OMl066ZltwpwAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGXefVQo+PbfxGvmzNlKxZ4VEZmdmTJng+yAa3auMGPORmLOvUrVkDk7MzPtmh0r+/IVx9qZsHM/UTGwn89iyXfuK1n7vqGaGvsOGRGR08OnXPlCLmvOVp37owpl+z6jxhb7Hh4RkdnirDlb8lwoIpJzPCdx36mXctV3PouePWa+0yOVsv1YSrVl1+x4wr5TrTbu29dlwZ0CAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGVeczE+OuwaXJixryOYK9i/di8ikqyxf/W+Whhxza6Nm58SKRd9swePTZiz1UjKNTtatj/fIiK1mQZztj7jO5bapP1r+rM55woNx7XSGiq4Zs9O+s5nIlNvzg5O2VcuiIjURBPmbKjqW7cSrlbN2cqccxfFnH2VS7TqW88REd/KjUpgv7aKOd9zOJu3r5UJRX3rOTIZ++qKubLvurLgTgEAoCgFAICiFAAAilIAAChKAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAMq86OfE8WOuwYmYvW8yafuuDxGRaNi+XyWR8u0dOX1yyJxtSPt2AqXjjp1AEnHNLvnW/Mhczr4zJajYd+WIiARV+/nJFUqu2XV1TebsWN63DypXtZ8fEZHAsS4nnel0zc5kuszZaNy3Q6gt2WjORiTnmj02at8JlM/NuGYnEr49WRK270pKheKu0YWgbM7Ga5x7zBJ15mx2zP58W3GnAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAECZ11zUJHyrKDo7O8zZTGOLa3ahNGnOTuV8qw4qcftX46P1ra7ZTak2c3Z25oRrdrXqW+cRE3t+dMa+EkNEpFS2P4fFsm91QaLWvo4gX7avIhARCWK+dQT5OfuxNzXY13OIiGQy9lUHYfE9hzHHGoVqud41O+lY/VEsTrlmB2XHcBGp8az/CJvfCkVEJOFYFdJ2QY9rdl29ffZwzPe6t+BOAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoCgFAICiFAAAyrzwI13f4BqcduzvaGm17wQSESlkq+Zs39iga3amyb6zKdYw3zU7CNt38Zw49Kprdqbo29uTTjabs9lswTV7Lm/flVRX59utk53J2cNhx+4bEUnU+PbIVOfsu3hyUyOu2WHHLp5o2L5rSkRkPGt/DhOxBtfsuYJ9dm56xjW75Ng1JSIyMzVpzkYTCdfsuNhfy+fPTbtmJ4KkOVuXsmetuFMAAChKAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoMzfpS+WfF/Vnpi0f/06lfKtaJDinDman/F9lT5V12LOZjK+454sDtvDFd/KhbJ948IfxkftKwPSCd9X6cOB/fxkMmnX7GjcvuKkUrFnRUTCEd9ajBOD9vNZymdds9tC9uelvbXdNbuct78mBof2u2ZPHR8zZ/tP+VbQtDXVufLtzfbXZ23G9/k4m7SvcolOH3XNjkTta2ViYfs6ISvuFAAAilIAAChKAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoMy7j0r5WdfggUl7PpiZdM1O1dt3mmSz9j0iIiL1c/a9PYka336ilpoOc/bdiy91zZ6enHLlw+WSOTs5NuSaHQpHzNnxCd9uqv7+4+ZsRALX7EQ47sqX5+z7b4KSPSsiMlFv32eUqvXtj8pN5czZseMnXbOrs/bXWznnu2YrGd/5KVXsu6wqs2XX7LFR+7Kxxkb7njERkVI5ZM7Wtte7ZltwpwAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGXefRSPZlyDJ4YGzdn+yUnX7EyjffdRteTbaVKfbjJno1H7jh8RkXLRvi+ludF+HCIiDfXNrvzsxJg5e/jgQdfs8aFhczYZ8e0nqjqyrS21rtmVqu9a2X+o35ztbvedn7GTR83ZSN7+fIuIRMv2PUyz476dZ/UZ+z6wixd0umYnkr5dY1NZ+46ngVn7zjMRkWS8wZw9Hjh3H0Xs1+G8VtdoE+4UAACKUgAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoCgFAICiFAAAilIAACjzmouWjvNdg4OS/WvjdQ31rtmRwP41/Vg86Zqdrrevl5jNFVyzi7OT9nDV99X453buceVHh4bM2ZTY1wWIiCy6wH4+q86fc3jKfu5b2lpcs+999DlXfnI2a87+p3f4VjocHhwxZ2dC9udERCQetq8WeenwadfsuXDInL30HRe4ZjfF7bNFRJqS5rc3iYZ9KzQkkTZHGxt8K2sqFfuai7Ex++vYijsFAICiFAAAilIAAChKAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAAAo83KQjvN8e0qiYXvfJJK+vSPlon3nTLFQcs2emLbv+QkFU67Z40MD5uze5190zc7nZ1z52pR9L8xkUHXNXt2VMmd3vnjYNXvRhUvM2dyMbyfQyqW+a/z89jZztjB9wjW7qzFuzg5O23fliIikauznvhryvTbbL+g2Zxt73umaPZcdd+XnxYfN2crErGu2ZxtYdc73HjQ9M2nODg0PumZbcKcAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQJm/7x6ORlyDM61d5mx2wr7+QUQkGnF8TT9ccc2ulOfM2XLJvm5DROSVffvN2WrFN3uuVHDlE+mEOVufqvUdSzhtzwZJ1+xs1r5a5Oig7znJ53zrCFKOa8t3NkWeOzhizl75watds0NF+0qU99a1u2YvetcqczaZtl8nIiKFrH2tiIhItFhvzmbKR1yzYzVN5mwo5rvGW5L2FSf5gm+ViwV3CgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUPYlQmXfjo1Uwr7vI0jZd5SIiMwV7ccSlH1bZ6Llojlb19njml0q/cqcDQWu0dLR4tsjE47aPw8MTfnO/fnT9v1EkZjvB+06r9WcPXLigGv22pW+8/m7F18wZ0/PukbLBxz7jC6/8irX7Ilh+66xkYN7XLPr62rs4RpHVkRyU8OufP+kY5dV2L7LSESksb7BnG1o9M3OztpfP8Gk7zmx4E4BAKAoBQCAohQAAIpSAAAoSgEAoCgFAICiFAAAilIAAChKAQCgKAUAgDKvuUg1dLgGF3L29RLVkH3bhojI5GzOnC3N+dYoNHfaf87ZWd/ugqA6Zz+Ohrhrdi5rf05ERE6N2fNL5ze6Zjel7GsxmhsyrtljM/bnvK6u1jX7yd17Xfntvz1ozv7fr37JNXv0tH0Vxa9/+bhrdlC0vzYnR0Zds6Onp83Z1s4u1+zZrO/1FnGsrImGY67ZAwMnzdlKyffarFQq5mxDbcQ124I7BQCAohQAAIpSAAAoSgEAoCgFAICiFAAAilIAAChKAQCgKAUAgKIUAACKUgAAKPPSoYnRIdfgTKbOnG3N1Lhmt7YsN2d7f/+Ma3ZDk33Pz8GXfbtyGmrtHXx8cMw1O5Xw9XtXa9qcbWlIuGYPTNp3H3W2+mYfO2XfxfPci6+6Zp8c8+3WWfmupeZsR9d81+z+Y0fN2WrOvuNHRCTm2ME1OF1wzU6W7Ht7Dh077ppdrvj2mMUcK9VWrlzpmn3RMnu+OOV775ybHbeHo74daRbcKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQJm3g+zZ86xr8CUXLzZn6xraXLMj4ao5WxO272IRETm4d485e/zVna7Z/SNT5mxNxDVaWuqSrnwQtu8cqk+3uma/+FKfOfvOBbWu2bXJenP2srUXu2b3Dwy78scGZszZXb/6N9fsPsex9PQscM2Wsv31031+u2t0bU3MnI1GfJ9JW+rt+7pEROqbms3ZBYuXuWZfvOJ95uxs0b5rSkRk544fm7PjYxOu2RbcKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQ5jUXK5e/wzW4JVUyZwdHTrhmnzrxW3P2+NFjrtmFYtmc7UjZsyIi5zean26RqiMrIpWKfb2AiEhns33NRbHqWxVSngvM2UODOdfs6Zlpc/bIsZOu2aOTWVe+GrJ/pjrS77vG62trzNmBft81Ho7Yz09NzHddrVl7mTm76N2Xuma/8JtfuPKhwP767NtnX28jIjJ8bL85m2rscM0uF2fN2bjz/FhwpwAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGVesNPa0uoafKT3d+bs8VHfzpm+g6+Ys5VS1TV71fwGczYI2/c7iYh41hOdGvHtVbJvyvmDhpZmc/blgTHX7HQ6ZM4ODJ52zR4aHTdnT41MuWbXpeKu/HjOvhNqz/4jrtnlsn12Z3OTa/bYrH3f1KX/9B7X7LXv32DOHjl22DW7rtF+zYqITE+MmLPRZMo1u+e8HnN2566drtmNCfu5H5r2vU9YcKcAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQJnXXAyNjroGD04Wzdnui1a5Zk9Pz5qz2cHjrtntnY3m7MvHfLPr6hPmbFthzjW7tsbX70dPTZizT+zY45p9/X+5yJwdHPL9nKeG7GsuauLmy1tERIrOlSj/89p/Mmd/8+IJ1+xn9w2Ys4dP27MiIvG0/RoP7XnJNfsXP/+hOXteZ6drdkkce2JEpL2zy5zNVn2zJ2amzdnzz/OtCCqO21e/ZJK+a9yCOwUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoCgFAICiFAAAilIAACjz4oxqELgGr1hl3wuTL/n231SCkDmbqXGNlt4TI+ZsrlT2Dc+W7NmIb6dJ78CkK396wr6Lpz4Td80OhyLm7MnT9l1GIiLVin2nVt65y2jjf73clV/1jvnm7HN7ffuJPvCehebsr/f2uWaHI/bnpaOx1jV74Oh+czYZ8r3upTjlig/l7T/n9MyMa3YhmDRnz7/oEtfsIGT/rJ4aPuqabcGdAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABl3qUwPNDvG5wbM2d/v7/XNbsuZl+jMDgz6Zp9auK0Odtab1+3ISIi8QZ7NFrvGn1eU9qVf3af/evxNbGKa/YrvX3m7OSEb81FsWhfLTI47TvucMR+XYmIROIJc7arJeWa/dhvD5qzqxaf55r9rsXd5mwm6fvcGA7sz/nomH2ljIiI7+yINNZnzNl41Pdz1kSbzNlYbZ1rdqFsX7kxnoi5ZltwpwAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGXefZSIOvf85O27j2KxuGv04KlBczad9M3uO2rffXTh+b6dMx3t9l0sM7O1rtnlYt6Vb66170x5tc+3o2Z4ZMKenZpzzZ7IVs3ZcMT3mee5F+z7hkRElvS0mbPTuaJr9jVXXGLOLr3AfhwiIlMz0+bstCMrIlKfcezsCvu2GYWc53NgyP4eFInXuGafmLa/T4xFfa/NkYI939Dc6JptwZ0CAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGVec9F/9JBr8FRruzl7+vQp1+zTI+Pm7AXNvq/Sz+tqMmcjNXWu2RNj9nURpWjKNfvgUM6V7x2cMWdH877PDqFsxZwtVXzrU/75qnebs+vevdA1+10ru135UqFszi6aZ7+uRETyYftKlNFJ+7kUEYnF7Oezrt63RqFjvv05L0z4XvfJlGOFhohUqvYVKicGs67Z81d3m7PVRME1e1FiqTnbkEm7ZltwpwAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAGXefXTpBz/kGhyE7HtHXj1y2DW7vc2+cygesx+HiMjQuH2PTGgy4ZpdzNl35XQ2TLtm93R3ufKrpvPm7K/3+XbUrOpKmrPz5ne4Zsej9s8xoxOTrtn9x6dc+bFJ+76pbNF+7kVEYomiOZvL+fb21CZqzNmatG+3zvipI+ZsuVJ1zZ6e9e14Stbar8P/8b8/5ZqdTtp3qu07uNM1OxWyv7+Fs77n0DTzTZ8IAPi7RSkAABSlAABQlAIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUKEgCAJL8MCLT7oG/+CBb5mzLU3Nrtk9PUvM2bGsb+fMrl//uzk7Ou7bldOcse+cqYv7djadmvL1e33avrdpNuvbrdNcnzFn6+pTrtl1afvsfL7gmp1p8u1hGug7ZM72DU+6ZkeCijnb3d3tmh0PeV4TprcHFXbkQzH760FEpLljvu9Y5uy7ktJNra7Z6ZT9Onxh13Ou2Y119tfEbN73/vZ/bv/RG2a4UwAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoCgFAICiFAAAilIAAChKAQCgotbgy797xjX4sis3mLP/+i/3u2avXL7CnH3p5Rdds1vqkubsXHHWNbujuc6cXbhshWt24Te+81N1ZM8/r901+x3vXGXOVlxHIpLL5eyzx4dcsyfGx1z5SDRizr5z6SLX7ELRvr6gtcl+XYmINLd2mrOnT51wzS6V7KtF0jHfZ9JocdqVPzlif31msiXXbKkU7dGcPSsiMpDNm7N1ad+qEAvuFAAAilIAAChKAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoMy7j/Y990vX4GyQsh+E+Sj+4MCLvzVnF9fFXbOPV9PmbGd7h2v2+PiEORub8+1Vmi7MufLVqn1HTWuj/TkREdn57G5z9vpPfMo1OxQJmbOPbbvXNTtR4/uMlC1WzNnRE6dcs3u6W83ZgVHftfLx//XfzdnHf/6Ia/arz//KnM1FfC/8UNy3Q2hhZ605e2rCvm9IRKQ+Y9+RFm3IuGbH6uz55gb7+6wVdwoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQFEKAABFKQAAlPl75h3NDa7BubL9K+xBtM01e+UHN5qzQyeOuGbHD7xgzhZK9lURIiJBJWvOPrfTvspDRKQpbf9Kv4hIKF5nzlZDMdfsWLxkzv7+2X9zza5raLEfR6LGNXt4ZMSVX7h4sTk7f9FFrtmtUfvqiu3b/901+4f33mHO9h8/4Jr9rkVLzdnhE32u2bUNvmu8vsb+HlQ3zzd7smRfnzO/Y75r9r7DR83Z40OTrtkfN2S4UwAAKEoBAKAoBQCAohQAAIpSAAAoSgEAoCgFAICiFAAAilIAAChKAQCgKAUAgDIvB3n5yEnX4Na2HnP2P3/0I67Z4XjSnN3xi1+6ZrfaVwJJqGrf8SMicrr/mDmbzeZds2fyVVc+3W7fIXT9P/831+y9e/eZs7/73Uuu2YnaBnO2qa3TNXuRc0fNvOa0OTs7MuiaPTVy0Jy9aF6ra/ZsOmXOLl26xDX7PevWm7O/f+xh1+zpaMiVPzFsfw3NlmZcs1ua7G8Ux0/ZX/ciIr981r77qMnzhmXEnQIAQFEKAABFKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAAZV5zsWzZKtfgZe/7kDmbrKlxzR45fcKcHR/pc82OzdlXF0yOT7hmT08UzNlq2HxqREQkFI+48vuPjJiz237yc9fs965Zbc4uX/Ee1+yL373GnE0kal2zc9lpV3548LA5e3jvq67Zy7vs5z8c9Z37w717zNkVSy5wze49al/R0Lhgnmv2/I42V/6FZ7abs8mk7z0oU29/n5ieGXPNTiXs6zw66hKu2RbcKQAAFKUAAFCUAgBAUQoAAEUpAAAUpQAAUJQCAEBRCgAARSkAABSlAABQlAIAQIWCIAjO9UEAAN4euFMAAChKAQCgKAUAgKIUAACKUgAAKEoBAKAoBQCAohQAAIpSAACo/wdd3gdz98rrDQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_random_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n",
      "Zawartość tensora obrazu:\n",
      "[[-0.2235294  -0.30196077 -0.26274508 ... -0.64705884 -0.6313726\n",
      "  -0.20784312]\n",
      " [-0.23921567 -0.3333333  -0.3333333  ... -0.654902   -0.62352943\n",
      "  -0.5921569 ]\n",
      " [-0.11372548  0.02745104  0.05882359 ... -0.60784316 -0.4980392\n",
      "  -0.60784316]\n",
      " ...\n",
      " [-0.2862745   0.5294118   0.77254903 ...  0.8352941   0.81960785\n",
      "   0.70980394]\n",
      " [ 0.04313731  0.77254903  0.79607844 ...  0.8352941   0.7647059\n",
      "   0.6313726 ]\n",
      " [ 0.5137255   0.8117647   0.8117647  ...  0.8039216   0.7411765\n",
      "   0.6627451 ]]\n"
     ]
    }
   ],
   "source": [
    "# Pobierz jeden batch z DataLoadera\n",
    "root_dir = r\"C:\\Users\\Micha\\SEM1_projects\\Deep_learning_projects\\project_1\\data\\test\"\n",
    "dataloader = load_png_images(root_dir, batch_size=1) \n",
    "data_iter = iter(dataloader)\n",
    "image, label = next(data_iter)\n",
    "\n",
    "# Wypisz kształt tensora\n",
    "print(image.shape)  \n",
    "print(\"Zawartość tensora obrazu:\")\n",
    "print(image.squeeze(0).numpy()[0])  # Usunięcie wymiaru batch dla czytelności\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartości piksela (0,0): tensor([[ 0.9843,  0.9922,  0.9922,  ...,  0.9922,  0.9608,  0.9294],\n",
      "        [ 1.0000,  0.9451,  0.9451,  ...,  0.9529,  0.9216,  0.3176],\n",
      "        [ 0.9922,  0.6000,  0.5529,  ...,  0.5686,  0.5686, -0.1843],\n",
      "        ...,\n",
      "        [ 0.9608,  0.4902,  0.3882,  ...,  0.5216,  0.4588, -0.2549],\n",
      "        [ 0.9216,  0.0667, -0.0275,  ...,  0.0667,  0.0275, -0.2941],\n",
      "        [ 0.4588, -0.3412, -0.3333,  ..., -0.2392, -0.2941, -0.2784]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Wartości piksela (0,0):\", image[0, 0, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_accuracy(loader, model):\n",
    "    model.eval()  # ustawienie modelu w tryb ewaluacji\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # nie śledzimy gradientów podczas testowania\n",
    "        for data, target in loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "class PNGDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.files = []\n",
    "        self.labels = []\n",
    "        self.label_to_idx = {}\n",
    "        \n",
    "        for idx, label in enumerate(os.listdir(root_dir)):\n",
    "            label_path = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                self.label_to_idx[label] = idx\n",
    "                for file in os.listdir(label_path):\n",
    "                    if file.endswith('.png'):\n",
    "                        self.files.append(os.path.join(label_path, file))\n",
    "                        self.labels.append(idx)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.files[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Funkcja do ładowania danych\n",
    "\n",
    "def load_png_images(root_dir, batch_size=32):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    \n",
    "    dataset = PNGDataset(root_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return dataloader, len(dataset.label_to_idx)\n",
    "\n",
    "# Definicja prostej sieci CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.softmax(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "# Funkcja do trenowania modelu\n",
    "def train_model(model, dataloader, num_epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for images, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, torch.tensor(labels, dtype=torch.long))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            accuracy = calculate_accuracy(dataloader, model)\n",
    "\n",
    "            # Wyświetlanie wyników po każdej epoce\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(dataloader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_4332\\2494929351.py:95: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = criterion(outputs, torch.tensor(labels, dtype=torch.long))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1737, Accuracy: 60.00%\n",
      "Epoch 1/10, Loss: 0.3473, Accuracy: 59.00%\n",
      "Epoch 1/10, Loss: 0.5212, Accuracy: 57.00%\n",
      "Epoch 1/10, Loss: 0.6887, Accuracy: 50.00%\n",
      "Epoch 2/10, Loss: 0.1665, Accuracy: 50.00%\n",
      "Epoch 2/10, Loss: 0.3304, Accuracy: 50.00%\n",
      "Epoch 2/10, Loss: 0.5162, Accuracy: 50.00%\n",
      "Epoch 2/10, Loss: 0.7026, Accuracy: 62.00%\n",
      "Epoch 3/10, Loss: 0.1562, Accuracy: 63.00%\n",
      "Epoch 3/10, Loss: 0.3177, Accuracy: 67.00%\n",
      "Epoch 3/10, Loss: 0.4919, Accuracy: 65.00%\n",
      "Epoch 3/10, Loss: 0.6684, Accuracy: 66.00%\n",
      "Epoch 4/10, Loss: 0.1595, Accuracy: 63.00%\n",
      "Epoch 4/10, Loss: 0.3203, Accuracy: 65.00%\n",
      "Epoch 4/10, Loss: 0.4940, Accuracy: 64.00%\n",
      "Epoch 4/10, Loss: 0.6486, Accuracy: 66.00%\n",
      "Epoch 5/10, Loss: 0.1558, Accuracy: 62.00%\n",
      "Epoch 5/10, Loss: 0.3206, Accuracy: 66.00%\n",
      "Epoch 5/10, Loss: 0.4824, Accuracy: 68.00%\n",
      "Epoch 5/10, Loss: 0.6542, Accuracy: 73.00%\n",
      "Epoch 6/10, Loss: 0.1515, Accuracy: 68.00%\n",
      "Epoch 6/10, Loss: 0.3064, Accuracy: 67.00%\n",
      "Epoch 6/10, Loss: 0.4722, Accuracy: 66.00%\n",
      "Epoch 6/10, Loss: 0.6037, Accuracy: 65.00%\n",
      "Epoch 7/10, Loss: 0.1512, Accuracy: 63.00%\n",
      "Epoch 7/10, Loss: 0.3317, Accuracy: 67.00%\n",
      "Epoch 7/10, Loss: 0.4821, Accuracy: 70.00%\n",
      "Epoch 7/10, Loss: 0.5891, Accuracy: 71.00%\n",
      "Epoch 8/10, Loss: 0.1368, Accuracy: 73.00%\n",
      "Epoch 8/10, Loss: 0.2921, Accuracy: 73.00%\n",
      "Epoch 8/10, Loss: 0.4369, Accuracy: 73.00%\n",
      "Epoch 8/10, Loss: 0.6039, Accuracy: 69.00%\n",
      "Epoch 9/10, Loss: 0.1475, Accuracy: 65.00%\n",
      "Epoch 9/10, Loss: 0.3116, Accuracy: 65.00%\n",
      "Epoch 9/10, Loss: 0.4584, Accuracy: 70.00%\n",
      "Epoch 9/10, Loss: 0.6103, Accuracy: 73.00%\n",
      "Epoch 10/10, Loss: 0.1547, Accuracy: 76.00%\n",
      "Epoch 10/10, Loss: 0.2806, Accuracy: 77.00%\n",
      "Epoch 10/10, Loss: 0.4415, Accuracy: 75.00%\n",
      "Epoch 10/10, Loss: 0.5723, Accuracy: 75.00%\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Ścieżka do katalogu z danymi (podkatalogi to etykiety)\n",
    "root_dir = r\"C:\\Users\\Micha\\SEM1_projects\\Deep_learning_projects\\project_1\\data\\sample\"\n",
    "\n",
    "# Załaduj dane\n",
    "dataloader, num_classes = load_png_images(root_dir, batch_size=32)\n",
    "\n",
    "# Stwórz model\n",
    "model = SimpleCNN(num_classes)\n",
    "\n",
    "# Trenowanie modelu\n",
    "train_model(model, dataloader, num_epochs=10, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
